{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to:\n",
    "- Load the snapshots of X and BlueSky data\n",
    "- Format them into threads (give replies/quotes their necessary context)\n",
    "- Filter by the politician-focused keyword lists\n",
    "- Export for narrative extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import io\n",
    "import json\n",
    "import os\n",
    "import pickle\n",
    "import re\n",
    "import uuid\n",
    "\n",
    "from itertools import product \n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data\n",
    "From Andrea's cleaned snapshots  \n",
    "\n",
    "2 types of filteres: text filtering on posts with keywords, user filtering with usernames (users and replies/quotes of them), then perform OR to get relevant posts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load keywords\n",
    "k_path = './data/keywords/bluesky_keywords_politicians.txt'\n",
    "with open(k_path, 'r') as f:\n",
    "    keywords_bluesky = f.readlines()\n",
    "keywords_bluesky = [k.strip() for k in keywords_bluesky]\n",
    "\n",
    "k_path = './data/keywords/x_keywords_politicians.txt'\n",
    "with open(k_path, 'r') as f:\n",
    "    keywords_x = f.readlines()\n",
    "keywords_x = [k.strip() for k in keywords_x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load usernames\n",
    "k_path = './data/keywords/bluesky_usernames_politicians.txt'\n",
    "with open(k_path, 'r') as f:\n",
    "    usernames_bluesky = f.readlines()\n",
    "usernames_bluesky = [k.strip().split('@')[1] for k in usernames_bluesky]\n",
    "\n",
    "k_path = './data/keywords/x_usernames_politicians.txt'\n",
    "with open(k_path, 'r') as f:\n",
    "    usernames_x = f.readlines()\n",
    "usernames_x = [k.strip().split('@')[1] for k in usernames_x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_x(\n",
    "    interactions, posts, users,\n",
    "    keywords, usernames,\n",
    "):\n",
    "    # Get relevant users (used to get all their posts)\n",
    "    relevant_users = users[\n",
    "        users['username'].isin(usernames)\n",
    "    ]\n",
    "\n",
    "    # Get relevant posts by keyword filter\n",
    "    relevant_posts = posts[\n",
    "        posts['full_text'].str.contains(\n",
    "            '|'.join(keywords), case=False, na=False, regex=True\n",
    "        )\n",
    "    ]\n",
    "\n",
    "    # Get all tweet IDs for relevant users and relevant posts\n",
    "    relevant_tweet_ids = set(\n",
    "        relevant_users['tweet_id'].apply(lambda x: x.split(',')).explode().tolist() + \\\n",
    "        relevant_posts['tweet_id'].tolist()\n",
    "    )\n",
    "\n",
    "    # Get interactions, posts and users for relevant tweets\n",
    "    filt_interactions = interactions[\n",
    "        interactions['tweet_id'].isin(relevant_tweet_ids)\n",
    "    ].reset_index(drop=True)\n",
    "\n",
    "    filt_posts = posts[\n",
    "        posts['tweet_id'].isin(relevant_tweet_ids)\n",
    "    ].reset_index(drop=True)\n",
    "\n",
    "    users.loc[:,'tweet_ids'] = users['tweet_id'].apply(lambda x: x.split(','))\n",
    "    users_exp = users.explode('tweet_ids')\n",
    "    filt_user_ids = users_exp[\n",
    "        users_exp['tweet_ids'].isin(relevant_tweet_ids)\n",
    "    ]['user_id'].unique()\n",
    "    filt_users = users[\n",
    "        users['user_id'].isin(filt_user_ids)\n",
    "    ].reset_index(drop=True)\n",
    "\n",
    "    return filt_interactions, filt_posts, filt_users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_bluesky(\n",
    "    interactions, posts, users,\n",
    "    keywords, usernames,\n",
    "):\n",
    "    # Get relevant users (used to get all their posts)\n",
    "    relevant_users = users[\n",
    "        users['username'].isin(usernames)\n",
    "    ]\n",
    "\n",
    "    # Get relevant posts by keyword filter\n",
    "    relevant_posts = posts[\n",
    "        posts['record_text'].str.contains(\n",
    "            '|'.join(keywords), case=False, na=False, regex=True\n",
    "        )\n",
    "    ]\n",
    "\n",
    "    # Get all uris for relevant users and relevant posts\n",
    "    relevant_uris = set(interactions[\n",
    "        interactions['did'].isin(relevant_users['did'].unique()) |\n",
    "        interactions['to_did'].isin(relevant_users['did'].unique()) |\n",
    "        interactions['uri'].isin(relevant_posts['uri'].unique())\n",
    "    ]['uri'].unique().tolist())\n",
    "\n",
    "    # Get interactions, posts and users for relevant posts\n",
    "    filt_interactions = interactions[\n",
    "        interactions['uri'].isin(relevant_uris)\n",
    "    ].reset_index(drop=True)\n",
    "\n",
    "    filt_posts = posts[\n",
    "        posts['uri'].isin(relevant_uris)\n",
    "    ].reset_index(drop=True)\n",
    "\n",
    "    filt_user_dids = set(\n",
    "        filt_interactions['did'].tolist() + filt_interactions['to_did'].tolist()\n",
    "    )\n",
    "    filt_users = users[\n",
    "        users['did'].isin(filt_user_dids)\n",
    "    ].reset_index(drop=True)\n",
    "\n",
    "    return filt_interactions, filt_posts, filt_users"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load\n",
    "Load day-by-day for X and Bluesky and export to consolidated interactions, posts, users files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_path = './data/snapshots/x/clean'\n",
    "bluesky_path = './data/snapshots/bluesky/clean'\n",
    "\n",
    "output_dir = './data/consolidated'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/50 [00:00<?, ?it/s]/tmp/ipykernel_3676186/860447381.py:23: DtypeWarning: Columns (11) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  users = pd.read_csv(path_, sep='\\t')\n",
      "  4%|▍         | 2/50 [00:05<01:58,  2.46s/it]/tmp/ipykernel_3676186/860447381.py:23: DtypeWarning: Columns (11) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  users = pd.read_csv(path_, sep='\\t')\n",
      "  6%|▌         | 3/50 [00:08<02:11,  2.80s/it]/tmp/ipykernel_3676186/860447381.py:23: DtypeWarning: Columns (10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  users = pd.read_csv(path_, sep='\\t')\n",
      "  8%|▊         | 4/50 [00:13<02:55,  3.82s/it]/tmp/ipykernel_3676186/860447381.py:19: DtypeWarning: Columns (10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  posts = pd.read_csv(path_, sep='\\t')\n",
      " 20%|██        | 10/50 [00:26<01:16,  1.91s/it]/tmp/ipykernel_3676186/860447381.py:19: DtypeWarning: Columns (12) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  posts = pd.read_csv(path_, sep='\\t')\n",
      " 42%|████▏     | 21/50 [00:41<00:39,  1.35s/it]/tmp/ipykernel_3676186/860447381.py:19: DtypeWarning: Columns (10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  posts = pd.read_csv(path_, sep='\\t')\n",
      " 58%|█████▊    | 29/50 [00:54<00:32,  1.53s/it]/tmp/ipykernel_3676186/860447381.py:23: DtypeWarning: Columns (8) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  users = pd.read_csv(path_, sep='\\t')\n",
      " 68%|██████▊   | 34/50 [01:08<00:47,  2.97s/it]/tmp/ipykernel_3676186/860447381.py:23: DtypeWarning: Columns (10,11) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  users = pd.read_csv(path_, sep='\\t')\n",
      " 70%|███████   | 35/50 [01:13<00:52,  3.53s/it]/tmp/ipykernel_3676186/860447381.py:19: DtypeWarning: Columns (10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  posts = pd.read_csv(path_, sep='\\t')\n",
      " 72%|███████▏  | 36/50 [01:16<00:44,  3.16s/it]/tmp/ipykernel_3676186/860447381.py:23: DtypeWarning: Columns (8) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  users = pd.read_csv(path_, sep='\\t')\n",
      " 78%|███████▊  | 39/50 [01:22<00:28,  2.55s/it]/tmp/ipykernel_3676186/860447381.py:19: DtypeWarning: Columns (10,12) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  posts = pd.read_csv(path_, sep='\\t')\n",
      " 80%|████████  | 40/50 [01:25<00:25,  2.60s/it]/tmp/ipykernel_3676186/860447381.py:23: DtypeWarning: Columns (11) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  users = pd.read_csv(path_, sep='\\t')\n",
      " 82%|████████▏ | 41/50 [01:28<00:23,  2.65s/it]/tmp/ipykernel_3676186/860447381.py:23: DtypeWarning: Columns (10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  users = pd.read_csv(path_, sep='\\t')\n",
      " 84%|████████▍ | 42/50 [01:30<00:21,  2.70s/it]/tmp/ipykernel_3676186/860447381.py:23: DtypeWarning: Columns (11) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  users = pd.read_csv(path_, sep='\\t')\n",
      " 88%|████████▊ | 44/50 [01:37<00:18,  3.02s/it]/tmp/ipykernel_3676186/860447381.py:23: DtypeWarning: Columns (11) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  users = pd.read_csv(path_, sep='\\t')\n",
      " 92%|█████████▏| 46/50 [01:42<00:10,  2.69s/it]/tmp/ipykernel_3676186/860447381.py:23: DtypeWarning: Columns (11) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  users = pd.read_csv(path_, sep='\\t')\n",
      "100%|██████████| 50/50 [01:50<00:00,  2.22s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(385208, 5) (368354, 34) (17933, 24)\n"
     ]
    }
   ],
   "source": [
    "# X\n",
    "all_interactions = []\n",
    "all_posts = []\n",
    "all_users = []\n",
    "\n",
    "dirs = os.listdir(x_path)\n",
    "for dirname in tqdm(dirs):\n",
    "    path = os.path.join(x_path, dirname)\n",
    "    fnames_interactions = ['interactions.csv', f'interactions_{dirname}.csv']\n",
    "    fnames_posts = ['posts.csv', f'posts_{dirname}.csv']\n",
    "    fnames_users = ['users.csv', f'users_{dirname}.csv']\n",
    "    for fname in fnames_interactions:\n",
    "        path_ = os.path.join(path, fname)\n",
    "        if os.path.exists(path_):\n",
    "            interactions = pd.read_csv(path_, sep='\\t')\n",
    "    for fname in fnames_posts:\n",
    "        path_ = os.path.join(path, fname)\n",
    "        if os.path.exists(path_):\n",
    "            posts = pd.read_csv(path_, sep='\\t')\n",
    "    for fname in fnames_users:\n",
    "        path_ = os.path.join(path, fname)\n",
    "        if os.path.exists(path_):\n",
    "            users = pd.read_csv(path_, sep='\\t')\n",
    "    \n",
    "    filt_interactions, filt_posts, filt_users = filter_x(\n",
    "        interactions, posts, users,\n",
    "        keywords_x, usernames_x,\n",
    "    )\n",
    "    all_interactions.append(filt_interactions)\n",
    "    all_posts.append(filt_posts)\n",
    "    all_users.append(filt_users)\n",
    "\n",
    "df_interactions = pd.concat(all_interactions).reset_index(drop=True)\n",
    "df_posts = pd.concat(all_posts).reset_index(drop=True)\n",
    "df_users = pd.concat(all_users).reset_index(drop=True)\n",
    "print(df_interactions.shape, df_posts.shape, df_users.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote to file\n"
     ]
    }
   ],
   "source": [
    "# fname = 'interactions_x_20250301_20250419.csv'\n",
    "# df_interactions.to_csv(os.path.join(output_dir, fname), index=False)\n",
    "\n",
    "# fname = 'posts_x_20250301_20250419.csv'\n",
    "# df_posts.to_csv(os.path.join(output_dir, fname), index=False)\n",
    "\n",
    "# fname = 'users_x_20250301_20250419.csv'\n",
    "# df_users.to_csv(os.path.join(output_dir, fname), index=False)\n",
    "\n",
    "# print('Wrote to file')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bluesky"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 1/50 [00:00<00:27,  1.81it/s]/tmp/ipykernel_3582690/1205475984.py:19: DtypeWarning: Columns (14) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  posts = pd.read_csv(path_, sep='\\t')\n",
      " 16%|█▌        | 8/50 [00:35<03:44,  5.34s/it]/tmp/ipykernel_3582690/1205475984.py:19: DtypeWarning: Columns (14) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  posts = pd.read_csv(path_, sep='\\t')\n",
      " 30%|███       | 15/50 [01:16<03:20,  5.71s/it]/tmp/ipykernel_3582690/1205475984.py:19: DtypeWarning: Columns (14) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  posts = pd.read_csv(path_, sep='\\t')\n",
      " 36%|███▌      | 18/50 [01:33<03:00,  5.64s/it]/tmp/ipykernel_3582690/1205475984.py:19: DtypeWarning: Columns (14) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  posts = pd.read_csv(path_, sep='\\t')\n",
      " 40%|████      | 20/50 [01:45<02:52,  5.75s/it]/tmp/ipykernel_3582690/1205475984.py:19: DtypeWarning: Columns (14) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  posts = pd.read_csv(path_, sep='\\t')\n",
      " 58%|█████▊    | 29/50 [02:37<01:57,  5.58s/it]/tmp/ipykernel_3582690/1205475984.py:19: DtypeWarning: Columns (14) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  posts = pd.read_csv(path_, sep='\\t')\n",
      " 60%|██████    | 30/50 [02:42<01:49,  5.48s/it]/tmp/ipykernel_3582690/1205475984.py:19: DtypeWarning: Columns (14) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  posts = pd.read_csv(path_, sep='\\t')\n",
      " 70%|███████   | 35/50 [03:10<01:23,  5.59s/it]/tmp/ipykernel_3582690/1205475984.py:19: DtypeWarning: Columns (14) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  posts = pd.read_csv(path_, sep='\\t')\n",
      " 80%|████████  | 40/50 [03:36<00:54,  5.46s/it]/tmp/ipykernel_3582690/1205475984.py:19: DtypeWarning: Columns (14) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  posts = pd.read_csv(path_, sep='\\t')\n",
      " 94%|█████████▍| 47/50 [04:15<00:17,  5.85s/it]/tmp/ipykernel_3582690/1205475984.py:19: DtypeWarning: Columns (14) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  posts = pd.read_csv(path_, sep='\\t')\n",
      " 96%|█████████▌| 48/50 [04:20<00:11,  5.62s/it]/tmp/ipykernel_3582690/1205475984.py:19: DtypeWarning: Columns (14) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  posts = pd.read_csv(path_, sep='\\t')\n",
      "100%|██████████| 50/50 [04:31<00:00,  5.43s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(460458, 6) (349796, 27) (274495, 10)\n"
     ]
    }
   ],
   "source": [
    "# Bluesky\n",
    "all_interactions = []\n",
    "all_posts = []\n",
    "all_users = []\n",
    "\n",
    "dirs = os.listdir(bluesky_path)\n",
    "for dirname in tqdm(dirs):\n",
    "    path = os.path.join(bluesky_path, dirname)\n",
    "    fnames_interactions = ['interactions.csv', f'interactions_{dirname}.csv']\n",
    "    fnames_posts = ['posts.csv', f'posts_{dirname}.csv']\n",
    "    fnames_users = ['users.csv', f'users_{dirname}.csv']\n",
    "    for fname in fnames_interactions:\n",
    "        path_ = os.path.join(path, fname)\n",
    "        if os.path.exists(path_):\n",
    "            interactions = pd.read_csv(path_, sep='\\t')\n",
    "    for fname in fnames_posts:\n",
    "        path_ = os.path.join(path, fname)\n",
    "        if os.path.exists(path_):\n",
    "            posts = pd.read_csv(path_, sep='\\t')\n",
    "    for fname in fnames_users:\n",
    "        path_ = os.path.join(path, fname)\n",
    "        if os.path.exists(path_):\n",
    "            users = pd.read_csv(path_, sep='\\t')\n",
    "    \n",
    "    filt_interactions, filt_posts, filt_users = filter_bluesky(\n",
    "        interactions, posts, users,\n",
    "        keywords_bluesky, usernames_bluesky,\n",
    "    )\n",
    "    all_interactions.append(filt_interactions)\n",
    "    all_posts.append(filt_posts)\n",
    "    all_users.append(filt_users)\n",
    "\n",
    "df_interactions = pd.concat(all_interactions).reset_index(drop=True)\n",
    "df_posts = pd.concat(all_posts).reset_index(drop=True)\n",
    "df_users = pd.concat(all_users).reset_index(drop=True)\n",
    "print(df_interactions.shape, df_posts.shape, df_users.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote to file\n"
     ]
    }
   ],
   "source": [
    "# fname = 'interactions_bluesky_20250301_20250419.csv'\n",
    "# df_interactions.to_csv(os.path.join(output_dir, fname), index=False)\n",
    "\n",
    "# fname = 'posts_bluesky_20250301_20250419.csv'\n",
    "# df_posts.to_csv(os.path.join(output_dir, fname), index=False)\n",
    "\n",
    "# fname = 'users_bluesky_20250301_20250419.csv'\n",
    "# df_users.to_csv(os.path.join(output_dir, fname), index=False)\n",
    "\n",
    "# print('Wrote to file')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "complexdata-kernel",
   "language": "python",
   "name": "complexdata-kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
