{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to:\n",
    "- Load the snapshots of X and BlueSky data\n",
    "- Format them into threads (give replies/quotes their necessary context)\n",
    "- Filter by the politician-focused keyword lists\n",
    "- Export for narrative extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nas/ckgfs/users/eboxer/complexdata/env/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import io\n",
    "import json\n",
    "import os\n",
    "import pickle\n",
    "import re\n",
    "import uuid\n",
    "\n",
    "from itertools import product \n",
    "\n",
    "import openai\n",
    "from openai import OpenAI\n",
    "from pydantic import BaseModel\n",
    "\n",
    "from typing import List\n",
    "\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv('./.env')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "key_openai = os.getenv('KEY_OPENAI')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data\n",
    "Load annotated samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(305, 19)\n",
      "(52, 19)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bucket</th>\n",
       "      <th>file</th>\n",
       "      <th>data_idx</th>\n",
       "      <th>matching_rules</th>\n",
       "      <th>data.author_id</th>\n",
       "      <th>data.conversation_id</th>\n",
       "      <th>data.text</th>\n",
       "      <th>data.referenced_tweets</th>\n",
       "      <th>includes.media</th>\n",
       "      <th>agent</th>\n",
       "      <th>agent_norm</th>\n",
       "      <th>action_or_event</th>\n",
       "      <th>action_or_event_norm</th>\n",
       "      <th>object</th>\n",
       "      <th>object_norm</th>\n",
       "      <th>good_example</th>\n",
       "      <th>notes</th>\n",
       "      <th>narrative</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>x</td>\n",
       "      <td>./data/snapshots/x/x-2025-02/26/03/x-1-2025-02...</td>\n",
       "      <td>36.0</td>\n",
       "      <td>[{'id': '1894436145368317952', 'tag': 'keyword...</td>\n",
       "      <td>1.347794e+18</td>\n",
       "      <td>1.894598e+18</td>\n",
       "      <td>So @MarkJCarney just lied on national tv @CBC ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[{'height': 2048, 'media_key': '3_189459794642...</td>\n",
       "      <td>@MarkJCarney</td>\n",
       "      <td>Mark Carney</td>\n",
       "      <td>lied</td>\n",
       "      <td>lied</td>\n",
       "      <td>on national tv</td>\n",
       "      <td>Canadian national TV</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>x</td>\n",
       "      <td>./data/snapshots/x/x-2025-02/26/03/x-1-2025-02...</td>\n",
       "      <td>21.0</td>\n",
       "      <td>[{'id': '1894436145368317952', 'tag': 'keyword...</td>\n",
       "      <td>8.421760e+17</td>\n",
       "      <td>1.894592e+18</td>\n",
       "      <td>Trudeau's MISTRESS Publicly HUMILIATED By Repo...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Trudeau's MISTRESS</td>\n",
       "      <td>Trudeau's mistress</td>\n",
       "      <td>HUMILIATED By</td>\n",
       "      <td>humiliated by</td>\n",
       "      <td>Reporter</td>\n",
       "      <td>reporter</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>x</td>\n",
       "      <td>./data/snapshots/x/x-2025-02/26/03/x-1-2025-02...</td>\n",
       "      <td>31.0</td>\n",
       "      <td>[{'id': '1894436145368317952', 'tag': 'keyword...</td>\n",
       "      <td>1.384664e+18</td>\n",
       "      <td>1.894589e+18</td>\n",
       "      <td>HILARIOUS! Mark Carney BOTCHES French Liberal ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Mark Carney</td>\n",
       "      <td>Mark Carney</td>\n",
       "      <td>BOTCHES</td>\n",
       "      <td>botches</td>\n",
       "      <td>French Liberal Debate</td>\n",
       "      <td>French Liberal Debate</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  bucket                                               file  data_idx  \\\n",
       "0      x  ./data/snapshots/x/x-2025-02/26/03/x-1-2025-02...      36.0   \n",
       "1      x  ./data/snapshots/x/x-2025-02/26/03/x-1-2025-02...      21.0   \n",
       "2      x  ./data/snapshots/x/x-2025-02/26/03/x-1-2025-02...      31.0   \n",
       "\n",
       "                                      matching_rules  data.author_id  \\\n",
       "0  [{'id': '1894436145368317952', 'tag': 'keyword...    1.347794e+18   \n",
       "1  [{'id': '1894436145368317952', 'tag': 'keyword...    8.421760e+17   \n",
       "2  [{'id': '1894436145368317952', 'tag': 'keyword...    1.384664e+18   \n",
       "\n",
       "   data.conversation_id                                          data.text  \\\n",
       "0          1.894598e+18  So @MarkJCarney just lied on national tv @CBC ...   \n",
       "1          1.894592e+18  Trudeau's MISTRESS Publicly HUMILIATED By Repo...   \n",
       "2          1.894589e+18  HILARIOUS! Mark Carney BOTCHES French Liberal ...   \n",
       "\n",
       "   data.referenced_tweets                                     includes.media  \\\n",
       "0                     NaN  [{'height': 2048, 'media_key': '3_189459794642...   \n",
       "1                     NaN                                                NaN   \n",
       "2                     NaN                                                NaN   \n",
       "\n",
       "                agent          agent_norm action_or_event  \\\n",
       "0        @MarkJCarney         Mark Carney            lied   \n",
       "1  Trudeau's MISTRESS  Trudeau's mistress   HUMILIATED By   \n",
       "2         Mark Carney         Mark Carney         BOTCHES   \n",
       "\n",
       "  action_or_event_norm                 object            object_norm  \\\n",
       "0                 lied         on national tv   Canadian national TV   \n",
       "1        humiliated by               Reporter               reporter   \n",
       "2              botches  French Liberal Debate  French Liberal Debate   \n",
       "\n",
       "   good_example  notes narrative  sentiment  \n",
       "0           NaN    NaN       NaN        NaN  \n",
       "1           NaN    NaN       NaN        NaN  \n",
       "2           NaN    NaN       NaN        NaN  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fname = f'./data/annotated/df_x_sample_filtered_20250226_20250227_annotated.xlsx'\n",
    "df_x = pd.read_excel(fname)\n",
    "print(df_x.shape)\n",
    "df_x = df_x[:52]\n",
    "print(df_x.shape)\n",
    "df_x[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10518, 18)\n",
      "(114, 18)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bucket</th>\n",
       "      <th>file</th>\n",
       "      <th>data_idx</th>\n",
       "      <th>commit.record.reply.parent.uri</th>\n",
       "      <th>commit.record.reply.root.uri</th>\n",
       "      <th>commit.record.text</th>\n",
       "      <th>commit.record.title</th>\n",
       "      <th>commit.record.embed.external.uri</th>\n",
       "      <th>agent</th>\n",
       "      <th>agent_norm</th>\n",
       "      <th>action_or_event</th>\n",
       "      <th>action_or_event_norm</th>\n",
       "      <th>object</th>\n",
       "      <th>object_norm</th>\n",
       "      <th>good_example</th>\n",
       "      <th>notes</th>\n",
       "      <th>narrative</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bluesky</td>\n",
       "      <td>./data/snapshots/bluesky/bluesky-2025-02/26/03...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>I called Governor Stitt’s (Oklahoma Governor) ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bluesky</td>\n",
       "      <td>./data/snapshots/bluesky/bluesky-2025-02/26/03...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>When I say I want you\\nMay every inch of you b...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bluesky</td>\n",
       "      <td>./data/snapshots/bluesky/bluesky-2025-02/26/03...</td>\n",
       "      <td>16.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Toast by Streetband may be a rap song by a whi...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://youtu.be/cmeby-7YpLk</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    bucket                                               file  data_idx  \\\n",
       "0  bluesky  ./data/snapshots/bluesky/bluesky-2025-02/26/03...       5.0   \n",
       "1  bluesky  ./data/snapshots/bluesky/bluesky-2025-02/26/03...       8.0   \n",
       "2  bluesky  ./data/snapshots/bluesky/bluesky-2025-02/26/03...      16.0   \n",
       "\n",
       "   commit.record.reply.parent.uri  commit.record.reply.root.uri  \\\n",
       "0                             NaN                           NaN   \n",
       "1                             NaN                           NaN   \n",
       "2                             NaN                           NaN   \n",
       "\n",
       "                                  commit.record.text  commit.record.title  \\\n",
       "0  I called Governor Stitt’s (Oklahoma Governor) ...                  NaN   \n",
       "1  When I say I want you\\nMay every inch of you b...                  NaN   \n",
       "2  Toast by Streetband may be a rap song by a whi...                  NaN   \n",
       "\n",
       "  commit.record.embed.external.uri agent agent_norm action_or_event  \\\n",
       "0                              NaN   NaN        NaN             NaN   \n",
       "1                              NaN   NaN        NaN             NaN   \n",
       "2     https://youtu.be/cmeby-7YpLk   NaN        NaN             NaN   \n",
       "\n",
       "  action_or_event_norm object object_norm  good_example  notes narrative  \\\n",
       "0                  NaN    NaN         NaN           NaN    NaN       NaN   \n",
       "1                  NaN    NaN         NaN           NaN    NaN       NaN   \n",
       "2                  NaN    NaN         NaN           NaN    NaN       NaN   \n",
       "\n",
       "   sentiment  \n",
       "0        NaN  \n",
       "1        NaN  \n",
       "2        NaN  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fname = f'./data/annotated/df_bluesky_sample_filtered_20250226_20250227_annotated.xlsx'\n",
    "df_bluesky = pd.read_excel(fname)\n",
    "print(df_bluesky.shape)\n",
    "df_bluesky = df_bluesky[:114]\n",
    "print(df_bluesky.shape)\n",
    "df_bluesky[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(api_key=key_openai)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'gpt-4o-mini-2024-07-18'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define json schema for extractions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NarrativeEvent(BaseModel):\n",
    "    agent: str\n",
    "    agent_norm: str\n",
    "    action_or_event: str\n",
    "    action_or_event_norm: str\n",
    "    object: str\n",
    "    object_norm: str\n",
    "    narrative: str\n",
    "    sentiment: int\n",
    "\n",
    "class NarrativeExtraction(BaseModel):\n",
    "    events: List[NarrativeEvent]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Few-shot examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [\n",
    "    'agent', 'agent_norm',\n",
    "    'action_or_event', 'action_or_event_norm',\n",
    "    'object', 'object_norm',\n",
    "    'narrative', 'sentiment',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def join_if_list(value):\n",
    "    if isinstance(value, (list, tuple)) or (hasattr(value, 'ndim') and value.ndim == 1):\n",
    "        return ', '.join(str(x) for x in value)\n",
    "    if pd.isna(value):\n",
    "        return \"\"\n",
    "    return value\n",
    "\n",
    "def is_list_like(value):\n",
    "    return isinstance(value, (list, tuple)) or (hasattr(value, 'ndim') and value.ndim == 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_x_examples = df_x[df_x['good_example'] == 1].groupby(['data.text']).agg({\n",
    "    col: list for col in cols\n",
    "}).reset_index()\n",
    "\n",
    "fewshot_inputs_x = []\n",
    "fewshot_outputs_x = []\n",
    "for index, row in df_x_examples.iterrows():\n",
    "    fewshot_inputs_x.append(row['data.text'])\n",
    "    prepared = {}\n",
    "    max_len = 1  # minimum 1 event per row\n",
    "    \n",
    "    # Process each column value. If it's missing, assign a default list;\n",
    "    # if list-like, use it as is; otherwise, wrap it in a one-element list.\n",
    "    for col in cols:\n",
    "        val = row[col]\n",
    "        if is_list_like(val):\n",
    "            prepared[col] = list(val)\n",
    "            if len(prepared[col]) > max_len:\n",
    "                max_len = len(prepared[col])\n",
    "        else:\n",
    "            prepared[col] = [val]\n",
    "    \n",
    "    # Pad any lists shorter than max_len with empty defaults\n",
    "    for col in cols:\n",
    "        if len(prepared[col]) < max_len:\n",
    "            pad_val = 0 if col == \"sentiment\" else \"\"\n",
    "            prepared[col].extend([pad_val] * (max_len - len(prepared[col])))\n",
    "    \n",
    "    # Create one event per index position and append to a list for that row\n",
    "    events = []\n",
    "    for i in range(max_len):\n",
    "        event = {\n",
    "            \"agent\": prepared[\"agent\"][i] if not pd.isna(prepared[\"agent\"][i]) else None,\n",
    "            \"agent_norm\": prepared[\"agent_norm\"][i] if not pd.isna(prepared[\"agent_norm\"][i]) else None,\n",
    "            \"action_or_event\": prepared[\"action_or_event\"][i] if not pd.isna(prepared[\"action_or_event\"][i]) else None,\n",
    "            \"action_or_event_norm\": prepared[\"action_or_event_norm\"][i] if not pd.isna(prepared[\"action_or_event_norm\"][i]) else None,\n",
    "            \"object\": prepared[\"object\"][i] if not pd.isna(prepared[\"object\"][i]) else None,\n",
    "            \"object_norm\": prepared[\"object_norm\"][i] if not pd.isna(prepared[\"object_norm\"][i]) else None,\n",
    "            \"narrative\": prepared[\"narrative\"][i] if not pd.isna(prepared[\"narrative\"][i]) else None,\n",
    "            \"sentiment\": prepared[\"sentiment\"][i] if not pd.isna(prepared[\"sentiment\"][i]) else None,\n",
    "        }\n",
    "        events.append(event)\n",
    "    \n",
    "    fewshot_outputs_x.append(events)\n",
    "fewshot_outputs_x[1] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bluesky_examples = df_bluesky[df_bluesky['good_example'] == 1].groupby(['commit.record.text']).agg({\n",
    "    col: list for col in cols\n",
    "}).reset_index()\n",
    "\n",
    "fewshot_inputs_bluesky = []\n",
    "fewshot_outputs_bluesky = []\n",
    "for index, row in df_bluesky_examples.iterrows():\n",
    "    fewshot_inputs_bluesky.append(row['commit.record.text'])\n",
    "    prepared = {}\n",
    "    max_len = 1  # minimum 1 event per row\n",
    "    \n",
    "    # Process each column value. If it's missing, assign a default list;\n",
    "    # if list-like, use it as is; otherwise, wrap it in a one-element list.\n",
    "    for col in cols:\n",
    "        val = row[col]\n",
    "        if is_list_like(val):\n",
    "            prepared[col] = list(val)\n",
    "            if len(prepared[col]) > max_len:\n",
    "                max_len = len(prepared[col])\n",
    "        else:\n",
    "            prepared[col] = [val]\n",
    "    \n",
    "    # Pad any lists shorter than max_len with empty defaults\n",
    "    for col in cols:\n",
    "        if len(prepared[col]) < max_len:\n",
    "            pad_val = 0 if col == \"sentiment\" else \"\"\n",
    "            prepared[col].extend([pad_val] * (max_len - len(prepared[col])))\n",
    "    \n",
    "    # Create one event per index position and append to a list for that row\n",
    "    events = []\n",
    "    for i in range(max_len):\n",
    "        event = {\n",
    "            \"agent\": prepared[\"agent\"][i] if not pd.isna(prepared[\"agent\"][i]) else None,\n",
    "            \"agent_norm\": prepared[\"agent_norm\"][i] if not pd.isna(prepared[\"agent_norm\"][i]) else None,\n",
    "            \"action_or_event\": prepared[\"action_or_event\"][i] if not pd.isna(prepared[\"action_or_event\"][i]) else None,\n",
    "            \"action_or_event_norm\": prepared[\"action_or_event_norm\"][i] if not pd.isna(prepared[\"action_or_event_norm\"][i]) else None,\n",
    "            \"object\": prepared[\"object\"][i] if not pd.isna(prepared[\"object\"][i]) else None,\n",
    "            \"object_norm\": prepared[\"object_norm\"][i] if not pd.isna(prepared[\"object_norm\"][i]) else None,\n",
    "            \"narrative\": prepared[\"narrative\"][i] if not pd.isna(prepared[\"narrative\"][i]) else None,\n",
    "            \"sentiment\": prepared[\"sentiment\"][i] if not pd.isna(prepared[\"sentiment\"][i]) else None,\n",
    "        }\n",
    "        events.append(event)\n",
    "    \n",
    "    fewshot_outputs_bluesky.append(events)\n",
    "fewshot_outputs_bluesky[2] = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prompting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are an expert at structured data extraction and narrative understanding from social media data, specializing in the 2025 Canadian Presidential election. You will be given unstructured text from a social media post and should convert it into the given structure, a list of events where each event contains the following elements, focusing on figures in Canadian (and related international) politics:\n",
      "\n",
      "agent: One who is/has done the event.\n",
      "agent_norm: Normalized form of agent.\n",
      "action_or_event: Action which the agent has taken.\n",
      "action_or_event_norm: Normalized form of action_or_event.\n",
      "object: One who is receiving the action or being acted upon.\n",
      "object_norm: Normalized form of object.\n",
      "narrative: Short, 1-sentence description of the larger narrative that this agent-action-object triple seems to be a part of.\n",
      "sentiment: 1, 0, -1. Whether the social media post is referring to the agent-action-object triple in a positive (1), neutral (0), or negative (-1) manner.\n",
      "\n",
      "A post may contain no events or multiple. Extract all identified events in the post. Elements may be explicitly found in the post or implicit. Elements that cannot be filled should be left as None. If the social media post's poster is extracted as an element, they should be referred to as \"User\". All other people can be identifed by their name and social media handle (if found in the post).\n"
     ]
    }
   ],
   "source": [
    "zeroshot_system_prompt = '''\n",
    "You are an expert at structured data extraction and narrative understanding from social media data, specializing in the 2025 Canadian Presidential election. You will be given unstructured text from a social media post and should convert it into the given structure, a list of events where each event contains the following elements, focusing on figures in Canadian (and related international) politics:\n",
    "\n",
    "agent: One who is/has done the event.\n",
    "agent_norm: Normalized form of agent.\n",
    "action_or_event: Action which the agent has taken.\n",
    "action_or_event_norm: Normalized form of action_or_event.\n",
    "object: One who is receiving the action or being acted upon.\n",
    "object_norm: Normalized form of object.\n",
    "narrative: Short, 1-sentence description of the larger narrative that this agent-action-object triple seems to be a part of.\n",
    "\n",
    "A post may contain no events or multiple. Extract all identified events in the post. Elements may be explicitly found in the post or implicit. Elements that cannot be filled should be left as None. If the social media post's poster is extracted as an element, they should be referred to as \"User\". All other people can be identifed by their name and social media handle (if found in the post).\n",
    "'''.strip()\n",
    "print(zeroshot_system_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are an expert at structured data extraction and narrative understanding from social media data, specializing in the 2025 Canadian Presidential election. You will be given unstructured text from a social media post and should convert it into the given structure, a list of events where each event contains the following elements, focusing on figures in Canadian (and related international) politics:\n",
      "\n",
      "agent: One who is/has done the event.\n",
      "agent_norm: Normalized form of agent.\n",
      "action_or_event: Action which the agent has taken.\n",
      "action_or_event_norm: Normalized form of action_or_event.\n",
      "object: One who is receiving the action or being acted upon.\n",
      "object_norm: Normalized form of object.\n",
      "narrative: Short, 1-sentence description of the larger narrative that this agent-action-object triple seems to be a part of.\n",
      "sentiment: 1, 0, -1. Whether the social media post is referring to the agent-action-object triple in a positive (1), neutral (0), or negative (-1) manner.\n",
      "\n",
      "A post may contain no events or multiple. Extract all identified events in the post. Elements may be explicitly found in the post or implicit. Elements that cannot be filled should be left as None. If the social media post's poster is extracted as an element, they should be referred to as \"User\". All other people can be identifed by their name and social media handle (if found in the post).\n",
      "\n",
      "Here are some examples of valid extractions:\n"
     ]
    }
   ],
   "source": [
    "fewshot_system_prompt = '''\n",
    "You are an expert at structured data extraction and narrative understanding from social media data, specializing in the 2025 Canadian Presidential election. You will be given unstructured text from a social media post and should convert it into the given structure, a list of events where each event contains the following elements, focusing on figures in Canadian (and related international) politics:\n",
    "\n",
    "agent: One who is/has done the event.\n",
    "agent_norm: Normalized form of agent.\n",
    "action_or_event: Action which the agent has taken.\n",
    "action_or_event_norm: Normalized form of action_or_event.\n",
    "object: One who is receiving the action or being acted upon.\n",
    "object_norm: Normalized form of object.\n",
    "narrative: Short, 1-sentence description of the larger narrative that this agent-action-object triple seems to be a part of.\n",
    "\n",
    "A post may contain no events or multiple. Extract all identified events in the post. Elements may be explicitly found in the post or implicit. Elements that cannot be filled should be left as None. If the social media post's poster is extracted as an element, they should be referred to as \"User\". All other people can be identifed by their name and social media handle (if found in the post).\n",
    "\n",
    "Here are some examples of valid extractions:\n",
    "'''.strip()\n",
    "print(fewshot_system_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bluesky-specific few-shot prompt\n",
    "fewshot_system_prompt_bluesky = f'''\n",
    "{fewshot_system_prompt}\n",
    "\n",
    "Example Input 1:\n",
    "{fewshot_inputs_bluesky[0]}\n",
    "Example Output 1:\n",
    "{fewshot_outputs_bluesky[0]}\n",
    "\n",
    "Example Input 2:\n",
    "{fewshot_inputs_bluesky[1]}\n",
    "Example Output 2:\n",
    "{fewshot_outputs_bluesky[1]}\n",
    "\n",
    "Example Input 3:\n",
    "{fewshot_inputs_bluesky[2]}\n",
    "Example Output 3:\n",
    "{fewshot_outputs_bluesky[2]}\n",
    "'''.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X-specific few-shot prompt\n",
    "fewshot_system_prompt_x = f'''\n",
    "{fewshot_system_prompt}\n",
    "\n",
    "Example Input 1:\n",
    "{fewshot_inputs_x[0]}\n",
    "Example Output 1:\n",
    "{fewshot_outputs_x[0]}\n",
    "\n",
    "Example Input 2:\n",
    "{fewshot_inputs_x[1]}\n",
    "Example Output 2:\n",
    "{fewshot_outputs_x[1]}\n",
    "\n",
    "Example Input 3:\n",
    "{fewshot_inputs_x[2]}\n",
    "Example Output 3:\n",
    "{fewshot_outputs_x[2]}\n",
    "'''.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bluesky"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zeroshot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE\n",
      "Final export to: gpt4omini_df_bluesky_sample_filtered_20250226_20250227_extractions_zeroshot\n"
     ]
    }
   ],
   "source": [
    "processed_data_dir = os.path.join('./data', 'processed')\n",
    "fname = 'gpt4omini_df_bluesky_sample_filtered_20250226_20250227_extractions_zeroshot'\n",
    "fname_parsed_rounds_in_prog = os.path.join(\n",
    "    processed_data_dir, f'in_prog_{fname}.pkl'\n",
    ")\n",
    "save_every = 10\n",
    "\n",
    "id2processed_text = {}\n",
    "for idx, row in enumerate(df_bluesky.iterrows()):\n",
    "    id_, row = row[0], row[1]\n",
    "    try:\n",
    "        completion = client.beta.chat.completions.parse(\n",
    "            model=model_name,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": zeroshot_system_prompt},\n",
    "                {\"role\": \"user\", \"content\": row['commit.record.text']}\n",
    "            ],\n",
    "            response_format=NarrativeExtraction,\n",
    "        )\n",
    "        message = completion.choices[0].message\n",
    "        try:\n",
    "            parsed_round = message.content\n",
    "        except:\n",
    "            # Parsing error\n",
    "            print(f'error_parsing round: {round_n}')\n",
    "            parsed_round = message\n",
    "    except:\n",
    "        # Invalid JSON\n",
    "        parsed_round = {}\n",
    "    id2processed_text[id_] = parsed_round\n",
    "\n",
    "    # Save intermittently\n",
    "    if (idx + 1) % save_every == 0:\n",
    "        with open(fname_parsed_rounds_in_prog, 'wb') as f:\n",
    "            pickle.dump(id2processed_text, f)\n",
    "print('DONE')\n",
    "\n",
    "processed_data_dir = os.path.join('./data', 'processed')\n",
    "fname_parsed_rounds = os.path.join(processed_data_dir, f'{fname}.pkl')\n",
    "\n",
    "with open(fname_parsed_rounds, 'wb') as f:\n",
    "    pickle.dump(id2processed_text, f)\n",
    "print('Final export to:', fname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fewshot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_data_dir = os.path.join('./data', 'processed')\n",
    "fname = 'gpt4omini_df_bluesky_sample_filtered_20250226_20250227_extractions_fewshot'\n",
    "fname_parsed_rounds_in_prog = os.path.join(\n",
    "    processed_data_dir, f'in_prog_{fname}.pkl'\n",
    ")\n",
    "save_every = 10\n",
    "\n",
    "id2processed_text = {}\n",
    "for idx, row in enumerate(df_bluesky.iterrows()):\n",
    "    id_, row = row[0], row[1]\n",
    "    try:\n",
    "        completion = client.beta.chat.completions.parse(\n",
    "            model=model_name,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": fewshot_system_prompt_bluesky},\n",
    "                {\"role\": \"user\", \"content\": row['commit.record.text']}\n",
    "            ],\n",
    "            response_format=NarrativeExtraction,\n",
    "        )\n",
    "        message = completion.choices[0].message\n",
    "        try:\n",
    "            parsed_round = message.content\n",
    "        except:\n",
    "            # Parsing error\n",
    "            print(f'error_parsing round: {round_n}')\n",
    "            parsed_round = message\n",
    "    except:\n",
    "        # Invalid JSON\n",
    "        parsed_round = {}\n",
    "    id2processed_text[id_] = parsed_round\n",
    "\n",
    "    # Save intermittently\n",
    "    if (idx + 1) % save_every == 0:\n",
    "        with open(fname_parsed_rounds_in_prog, 'wb') as f:\n",
    "            pickle.dump(id2processed_text, f)\n",
    "print('DONE')\n",
    "\n",
    "processed_data_dir = os.path.join('./data', 'processed')\n",
    "fname_parsed_rounds = os.path.join(processed_data_dir, f'{fname}.pkl')\n",
    "\n",
    "with open(fname_parsed_rounds, 'wb') as f:\n",
    "    pickle.dump(id2processed_text, f)\n",
    "print('Final export to:', fname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zeroshot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE\n",
      "Final export to: gpt4omini_df_x_sample_filtered_20250226_20250227_extractions_zeroshot\n"
     ]
    }
   ],
   "source": [
    "processed_data_dir = os.path.join('./data', 'processed')\n",
    "fname = 'gpt4omini_df_x_sample_filtered_20250226_20250227_extractions_zeroshot'\n",
    "fname_parsed_rounds_in_prog = os.path.join(\n",
    "    processed_data_dir, f'in_prog_{fname}.pkl'\n",
    ")\n",
    "save_every = 10\n",
    "\n",
    "id2processed_text = {}\n",
    "for idx, row in enumerate(df_x.iterrows()):\n",
    "    id_, row = row[0], row[1]\n",
    "    try:\n",
    "        completion = client.beta.chat.completions.parse(\n",
    "            model=model_name,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": zeroshot_system_prompt},\n",
    "                {\"role\": \"user\", \"content\": row['data.text']}\n",
    "            ],\n",
    "            response_format=NarrativeExtraction,\n",
    "        )\n",
    "        message = completion.choices[0].message\n",
    "        try:\n",
    "            parsed_round = message.content\n",
    "        except:\n",
    "            # Parsing error\n",
    "            print(f'error_parsing round: {round_n}')\n",
    "            parsed_round = message\n",
    "    except:\n",
    "        # Invalid JSON\n",
    "        parsed_round = {}\n",
    "    id2processed_text[id_] = parsed_round\n",
    "\n",
    "    # Save intermittently\n",
    "    if (idx + 1) % save_every == 0:\n",
    "        with open(fname_parsed_rounds_in_prog, 'wb') as f:\n",
    "            pickle.dump(id2processed_text, f)\n",
    "print('DONE')\n",
    "\n",
    "processed_data_dir = os.path.join('./data', 'processed')\n",
    "fname_parsed_rounds = os.path.join(processed_data_dir, f'{fname}.pkl')\n",
    "\n",
    "with open(fname_parsed_rounds, 'wb') as f:\n",
    "    pickle.dump(id2processed_text, f)\n",
    "print('Final export to:', fname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fewshot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE\n",
      "Final export to: gpt4omini_df_x_sample_filtered_20250226_20250227_extractions_fewshot\n"
     ]
    }
   ],
   "source": [
    "processed_data_dir = os.path.join('./data', 'processed')\n",
    "fname = 'gpt4omini_df_x_sample_filtered_20250226_20250227_extractions_fewshot'\n",
    "fname_parsed_rounds_in_prog = os.path.join(\n",
    "    processed_data_dir, f'in_prog_{fname}.pkl'\n",
    ")\n",
    "save_every = 10\n",
    "\n",
    "id2processed_text = {}\n",
    "for idx, row in enumerate(df_x.iterrows()):\n",
    "    id_, row = row[0], row[1]\n",
    "    try:\n",
    "        completion = client.beta.chat.completions.parse(\n",
    "            model=model_name,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": fewshot_system_prompt_x},\n",
    "                {\"role\": \"user\", \"content\": row['data.text']}\n",
    "            ],\n",
    "            response_format=NarrativeExtraction,\n",
    "        )\n",
    "        message = completion.choices[0].message\n",
    "        try:\n",
    "            parsed_round = message.content\n",
    "        except:\n",
    "            # Parsing error\n",
    "            print(f'error_parsing round: {round_n}')\n",
    "            parsed_round = message\n",
    "    except:\n",
    "        # Invalid JSON\n",
    "        parsed_round = {}\n",
    "    id2processed_text[id_] = parsed_round\n",
    "\n",
    "    # Save intermittently\n",
    "    if (idx + 1) % save_every == 0:\n",
    "        with open(fname_parsed_rounds_in_prog, 'wb') as f:\n",
    "            pickle.dump(id2processed_text, f)\n",
    "print('DONE')\n",
    "\n",
    "processed_data_dir = os.path.join('./data', 'processed')\n",
    "fname_parsed_rounds = os.path.join(processed_data_dir, f'{fname}.pkl')\n",
    "\n",
    "with open(fname_parsed_rounds, 'wb') as f:\n",
    "    pickle.dump(id2processed_text, f)\n",
    "print('Final export to:', fname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate extractions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the sentence-transformers model.\n",
    "model = SentenceTransformer('all-mpnet-base-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extraction_to_text_by_fields(extraction, keys):\n",
    "    \"\"\"\n",
    "    Convert an extraction dict into a single string by concatenating\n",
    "    the values from the specified keys.\n",
    "    If a value is a list or tuple, its elements are joined with a space.\n",
    "    \"\"\"\n",
    "    parts = []\n",
    "    for key in keys:\n",
    "        value = extraction.get(key, \"\")\n",
    "        if isinstance(value, (list, tuple)):\n",
    "            parts.append(\" \".join(map(str, value)))\n",
    "        else:\n",
    "            parts.append(str(value))\n",
    "    return \" \".join(parts).strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_extraction_similarity_by_fields(gt_extractions, new_extractions, model, keys):\n",
    "    \"\"\"\n",
    "    Compute a similarity score based on comparing extracted information.\n",
    "    \n",
    "    - `gt_extractions`: list of ground-truth extraction dicts.\n",
    "    - `new_extractions`: list of new extraction dicts.\n",
    "    - `keys`: list of keys to use for building the text string\n",
    "       (e.g. [\"agent_norm\", \"action_or_event_norm\", \"object_norm\"]).\n",
    "       \n",
    "    Steps:\n",
    "      * Convert each extraction (ground-truth and new) into a text string by concatenating\n",
    "        the specified fields.\n",
    "      * Encode these strings using the sentence-transformers model.\n",
    "      * Compute a cosine similarity matrix.\n",
    "      * Use the Hungarian algorithm to optimally match ground-truth to new extraction pairs.\n",
    "      * Penalize for any extra or missing extractions by dividing the sum by the maximum\n",
    "        number of extractions on either side.\n",
    "        \n",
    "    Returns a float score between 0 and 1.\n",
    "    \"\"\"\n",
    "    # If either side is empty, return 0.\n",
    "    if not gt_extractions or not new_extractions:\n",
    "        return 0.0\n",
    "\n",
    "    # Build the text representations.\n",
    "    gt_texts = [extraction_to_text_by_fields(e, keys) for e in gt_extractions]\n",
    "    new_texts = [extraction_to_text_by_fields(e, keys) for e in new_extractions]\n",
    "    \n",
    "    # Encode texts into embeddings.\n",
    "    gt_embeddings = model.encode(gt_texts, convert_to_tensor=True)\n",
    "    new_embeddings = model.encode(new_texts, convert_to_tensor=True)\n",
    "    \n",
    "    # Compute cosine similarity matrix.\n",
    "    cosine_scores = util.cos_sim(gt_embeddings, new_embeddings)\n",
    "    sim_matrix = cosine_scores.cpu().numpy()\n",
    "\n",
    "    # Use Hungarian algorithm (linear_sum_assignment) to maximize similarity.\n",
    "    # Since linear_sum_assignment minimizes cost, we use negative similarities.\n",
    "    row_ind, col_ind = linear_sum_assignment(-sim_matrix)\n",
    "    sum_sim = sim_matrix[row_ind, col_ind].sum()\n",
    "\n",
    "    # Divide by the maximum number of extractions to penalize unpaired events.\n",
    "    total_possible = max(len(gt_extractions), len(new_extractions))\n",
    "    score = sum_sim / total_possible\n",
    "    return float(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_list_like(x):\n",
    "    \"\"\"Check if x is list-like (list, tuple, or a 1D numpy array).\"\"\"\n",
    "    return isinstance(x, (list, tuple)) or (hasattr(x, 'ndim') and x.ndim == 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_df_to_extractions_dict(df):\n",
    "    \"\"\"\n",
    "    Convert the ground-truth dataframe into a mapping of the form:\n",
    "    \n",
    "        { row_index: [extraction_dict, extraction_dict, ...], ... }\n",
    "        \n",
    "    Each extraction_dict contains the keys:\n",
    "        \"agent\", \"agent_norm\", \"action_or_event\", \"action_or_event_norm\",\n",
    "        \"object\", \"object_norm\", \"narrative\", \"sentiment\"\n",
    "    \n",
    "    For each row, scalar values are converted into a single-element list; \n",
    "    list-like values remain unchanged. If the number of extraction items differ \n",
    "    across fields, shorter lists are padded with default values (\"\" for text, 0 for sentiment).\n",
    "    \n",
    "    Parameters:\n",
    "      - df: pd.DataFrame containing your ground-truth extraction columns.\n",
    "    \n",
    "    Returns:\n",
    "      - A dictionary mapping each row index (from the original dataframe) to a list of extraction dictionaries.\n",
    "    \"\"\"\n",
    "    result = {}\n",
    "    \n",
    "    extraction_fields = [\n",
    "        \"agent\", \"agent_norm\", \"action_or_event\", \"action_or_event_norm\",\n",
    "        \"object\", \"object_norm\", \"narrative\", \"sentiment\"\n",
    "    ]\n",
    "    \n",
    "    for row_idx, row in df.iterrows():\n",
    "        extraction_data = {}\n",
    "        max_len = 1  # Minimum one extraction per row\n",
    "        \n",
    "        # Wrap each field into a list if necessary (or use defaults if missing or NaN)\n",
    "        for col in extraction_fields:\n",
    "            if col not in row or pd.isna(row[col]):\n",
    "                extraction_data[col] = [0] if col == \"sentiment\" else [\"\"]\n",
    "            else:\n",
    "                value = row[col]\n",
    "                if is_list_like(value):\n",
    "                    extraction_data[col] = list(value)\n",
    "                else:\n",
    "                    extraction_data[col] = [value]\n",
    "            \n",
    "            # Update max_len if any column has more extractions\n",
    "            if len(extraction_data[col]) > max_len:\n",
    "                max_len = len(extraction_data[col])\n",
    "        \n",
    "        # Pad columns that have fewer than max_len extraction items\n",
    "        for col in extraction_fields:\n",
    "            if len(extraction_data[col]) < max_len:\n",
    "                pad_val = 0 if col == \"sentiment\" else \"\"\n",
    "                extraction_data[col].extend([pad_val] * (max_len - len(extraction_data[col])))\n",
    "        \n",
    "        # Create a list of extraction dictionaries, one per extraction event\n",
    "        extractions = []\n",
    "        for i in range(max_len):\n",
    "            # Convert sentiment to int if possible\n",
    "            sentiment_val = extraction_data[\"sentiment\"][i]\n",
    "            try:\n",
    "                sentiment_val = int(sentiment_val)\n",
    "            except (ValueError, TypeError):\n",
    "                sentiment_val = 0\n",
    "            \n",
    "            extraction = {\n",
    "                \"agent\": extraction_data[\"agent\"][i],\n",
    "                \"agent_norm\": extraction_data[\"agent_norm\"][i],\n",
    "                \"action_or_event\": extraction_data[\"action_or_event\"][i],\n",
    "                \"action_or_event_norm\": extraction_data[\"action_or_event_norm\"][i],\n",
    "                \"object\": extraction_data[\"object\"][i],\n",
    "                \"object_norm\": extraction_data[\"object_norm\"][i],\n",
    "                \"narrative\": extraction_data[\"narrative\"][i],\n",
    "                \"sentiment\": sentiment_val\n",
    "            }\n",
    "            extractions.append(extraction)\n",
    "        \n",
    "        # Map the original row index to its list of extraction dictionaries.\n",
    "        result[row_idx] = extractions\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_outputs(id2processed, id2groundtruth):\n",
    "    id2score_type1 = {}  # Textualized triples\n",
    "    id2score_type2 = {}  # Agent\n",
    "    id2score_type3 = {}  # Action or event\n",
    "    id2score_type4 = {}  # Object\n",
    "\n",
    "    for id_, gt_extractions in id2groundtruth.items():\n",
    "        new_extractions = id2processed.get(id_, [])\n",
    "        \n",
    "        # Ensure both sides are lists.\n",
    "        if not isinstance(gt_extractions, list):\n",
    "            gt_extractions = [gt_extractions] if gt_extractions else []\n",
    "        if not isinstance(new_extractions, list):\n",
    "            new_extractions = [new_extractions] if new_extractions else []\n",
    "        \n",
    "        # Compute score 1\n",
    "        score1 = compute_extraction_similarity_by_fields(\n",
    "            gt_extractions, new_extractions, model,\n",
    "            keys=[\"agent_norm\", \"action_or_event_norm\", \"object_norm\"]\n",
    "        )\n",
    "        # Compute score 2\n",
    "        score2 = compute_extraction_similarity_by_fields(\n",
    "            gt_extractions, new_extractions, model,\n",
    "            keys=[\"agent_norm\"]\n",
    "        )\n",
    "        # Compute score 3\n",
    "        score3 = compute_extraction_similarity_by_fields(\n",
    "            gt_extractions, new_extractions, model,\n",
    "            keys=[\"action_or_event_norm\"]\n",
    "        )\n",
    "        # Compute score 4\n",
    "        score4 = compute_extraction_similarity_by_fields(\n",
    "            gt_extractions, new_extractions, model,\n",
    "            keys=[\"object_norm\"]\n",
    "        )\n",
    "        \n",
    "        id2score_type1[id_] = score1\n",
    "        id2score_type2[id_] = score2\n",
    "        id2score_type3[id_] = score3\n",
    "        id2score_type4[id_] = score4\n",
    "\n",
    "    # Combine into one dataframe and return\n",
    "    df_results = pd.DataFrame(list(id2score_type1.items()), columns=['id', 'triple_score']).set_index('id').join(\n",
    "        pd.DataFrame(list(id2score_type2.items()), columns=['id', 'agent_score']).set_index('id')\n",
    "    ).join(\n",
    "        pd.DataFrame(list(id2score_type3.items()), columns=['id', 'action_score']).set_index('id')\n",
    "    ).join(\n",
    "        pd.DataFrame(list(id2score_type4.items()), columns=['id', 'object_score']).set_index('id')\n",
    "    )\n",
    "    return df_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ground truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52\n",
      "114\n"
     ]
    }
   ],
   "source": [
    "gt_x = convert_df_to_extractions_dict(df_x)\n",
    "print(len(gt_x))\n",
    "\n",
    "gt_bluesky = convert_df_to_extractions_dict(df_bluesky)\n",
    "print(len(gt_bluesky))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bluesky"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zeroshot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read from: ./data/annotated/df_bluesky_sample_filtered_20250226_20250227_annotated.xlsx\n"
     ]
    }
   ],
   "source": [
    "processed_data_dir = os.path.join('./data', 'processed')\n",
    "fname_parsed_rounds = os.path.join(processed_data_dir, f'{fname}.pkl')\n",
    "\n",
    "fname_parsed_rounds = '/nas/ckgfs/users/eboxer/complexdata/data/processed/gpt4omini_df_bluesky_sample_filtered_20250226_20250227_extractions_zeroshot.pkl'\n",
    "with open(fname_parsed_rounds, 'rb') as f:\n",
    "    id2processed_text = pickle.load(f)\n",
    "id2processed_text = {id_: json.loads(text)['events'] for id_, text in id2processed_text.items()}\n",
    "print('Read from:', fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>triple_score</th>\n",
       "      <th>agent_score</th>\n",
       "      <th>action_score</th>\n",
       "      <th>object_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>114.000000</td>\n",
       "      <td>114.000000</td>\n",
       "      <td>114.000000</td>\n",
       "      <td>114.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.164413</td>\n",
       "      <td>0.193534</td>\n",
       "      <td>0.107973</td>\n",
       "      <td>0.161881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.263555</td>\n",
       "      <td>0.295711</td>\n",
       "      <td>0.165689</td>\n",
       "      <td>0.250512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-0.043402</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.009241</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.045057</td>\n",
       "      <td>0.085689</td>\n",
       "      <td>0.045701</td>\n",
       "      <td>0.067722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.195917</td>\n",
       "      <td>0.255459</td>\n",
       "      <td>0.161195</td>\n",
       "      <td>0.221194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       triple_score  agent_score  action_score  object_score\n",
       "count    114.000000   114.000000    114.000000    114.000000\n",
       "mean       0.164413     0.193534      0.107973      0.161881\n",
       "std        0.263555     0.295711      0.165689      0.250512\n",
       "min       -0.043402     0.000000     -0.009241      0.000000\n",
       "25%        0.000000     0.000000      0.000000      0.000000\n",
       "50%        0.045057     0.085689      0.045701      0.067722\n",
       "75%        0.195917     0.255459      0.161195      0.221194\n",
       "max        1.000000     1.000000      1.000000      1.000000"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results = evaluate_outputs(id2processed_text, gt_bluesky)\n",
    "df_results.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fewshot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read from: ./data/annotated/df_bluesky_sample_filtered_20250226_20250227_annotated.xlsx\n"
     ]
    }
   ],
   "source": [
    "processed_data_dir = os.path.join('./data', 'processed')\n",
    "fname_parsed_rounds = os.path.join(processed_data_dir, f'{fname}.pkl')\n",
    "\n",
    "fname_parsed_rounds = '/nas/ckgfs/users/eboxer/complexdata/data/processed/gpt4omini_df_bluesky_sample_filtered_20250226_20250227_extractions_fewshot.pkl'\n",
    "with open(fname_parsed_rounds, 'rb') as f:\n",
    "    id2processed_text = pickle.load(f)\n",
    "id2processed_text = {id_: json.loads(text)['events'] for id_, text in id2processed_text.items()}\n",
    "print('Read from:', fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>triple_score</th>\n",
       "      <th>agent_score</th>\n",
       "      <th>action_score</th>\n",
       "      <th>object_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>114.000000</td>\n",
       "      <td>114.000000</td>\n",
       "      <td>114.000000</td>\n",
       "      <td>114.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.165010</td>\n",
       "      <td>0.184633</td>\n",
       "      <td>0.102467</td>\n",
       "      <td>0.159101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.296769</td>\n",
       "      <td>0.320898</td>\n",
       "      <td>0.184931</td>\n",
       "      <td>0.290299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.176765</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.118678</td>\n",
       "      <td>0.189173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       triple_score  agent_score  action_score  object_score\n",
       "count    114.000000   114.000000    114.000000    114.000000\n",
       "mean       0.165010     0.184633      0.102467      0.159101\n",
       "std        0.296769     0.320898      0.184931      0.290299\n",
       "min        0.000000     0.000000      0.000000      0.000000\n",
       "25%        0.000000     0.000000      0.000000      0.000000\n",
       "50%        0.000000     0.000000      0.000000      0.000000\n",
       "75%        0.176765     0.250000      0.118678      0.189173\n",
       "max        1.000000     1.000000      1.000000      1.000000"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results = evaluate_outputs(id2processed_text, gt_bluesky)\n",
    "df_results.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zeroshot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read from: ./data/annotated/df_bluesky_sample_filtered_20250226_20250227_annotated.xlsx\n"
     ]
    }
   ],
   "source": [
    "processed_data_dir = os.path.join('./data', 'processed')\n",
    "fname_parsed_rounds = os.path.join(processed_data_dir, f'{fname}.pkl')\n",
    "\n",
    "fname_parsed_rounds = '/nas/ckgfs/users/eboxer/complexdata/data/processed/gpt4omini_df_x_sample_filtered_20250226_20250227_extractions_zeroshot.pkl'\n",
    "with open(fname_parsed_rounds, 'rb') as f:\n",
    "    id2processed_text = pickle.load(f)\n",
    "id2processed_text = {id_: json.loads(text)['events'] for id_, text in id2processed_text.items()}\n",
    "print('Read from:', fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>triple_score</th>\n",
       "      <th>agent_score</th>\n",
       "      <th>action_score</th>\n",
       "      <th>object_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>52.000000</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>52.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.380657</td>\n",
       "      <td>0.419167</td>\n",
       "      <td>0.277850</td>\n",
       "      <td>0.353249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.331304</td>\n",
       "      <td>0.359794</td>\n",
       "      <td>0.254691</td>\n",
       "      <td>0.310749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.093530</td>\n",
       "      <td>0.111735</td>\n",
       "      <td>0.100797</td>\n",
       "      <td>0.113141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.280021</td>\n",
       "      <td>0.325341</td>\n",
       "      <td>0.194944</td>\n",
       "      <td>0.242954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.743036</td>\n",
       "      <td>0.592641</td>\n",
       "      <td>0.372361</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.966931</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       triple_score  agent_score  action_score  object_score\n",
       "count     52.000000    52.000000     52.000000     52.000000\n",
       "mean       0.380657     0.419167      0.277850      0.353249\n",
       "std        0.331304     0.359794      0.254691      0.310749\n",
       "min        0.000000     0.000000      0.000000      0.000000\n",
       "25%        0.093530     0.111735      0.100797      0.113141\n",
       "50%        0.280021     0.325341      0.194944      0.242954\n",
       "75%        0.743036     0.592641      0.372361      0.500000\n",
       "max        0.966931     1.000000      1.000000      1.000000"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results = evaluate_outputs(id2processed_text, gt_x)\n",
    "df_results.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fewshot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read from: ./data/annotated/df_bluesky_sample_filtered_20250226_20250227_annotated.xlsx\n"
     ]
    }
   ],
   "source": [
    "processed_data_dir = os.path.join('./data', 'processed')\n",
    "fname_parsed_rounds = os.path.join(processed_data_dir, f'{fname}.pkl')\n",
    "\n",
    "fname_parsed_rounds = '/nas/ckgfs/users/eboxer/complexdata/data/processed/gpt4omini_df_x_sample_filtered_20250226_20250227_extractions_fewshot.pkl'\n",
    "with open(fname_parsed_rounds, 'rb') as f:\n",
    "    id2processed_text = pickle.load(f)\n",
    "id2processed_text = {id_: json.loads(text)['events'] for id_, text in id2processed_text.items()}\n",
    "print('Read from:', fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>triple_score</th>\n",
       "      <th>agent_score</th>\n",
       "      <th>action_score</th>\n",
       "      <th>object_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>52.000000</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>52.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.401956</td>\n",
       "      <td>0.441171</td>\n",
       "      <td>0.293919</td>\n",
       "      <td>0.391227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.362698</td>\n",
       "      <td>0.369074</td>\n",
       "      <td>0.280289</td>\n",
       "      <td>0.351624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.062911</td>\n",
       "      <td>0.111642</td>\n",
       "      <td>0.085490</td>\n",
       "      <td>0.092142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.348325</td>\n",
       "      <td>0.393829</td>\n",
       "      <td>0.220333</td>\n",
       "      <td>0.306221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.798207</td>\n",
       "      <td>0.745034</td>\n",
       "      <td>0.446169</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       triple_score  agent_score  action_score  object_score\n",
       "count     52.000000    52.000000     52.000000     52.000000\n",
       "mean       0.401956     0.441171      0.293919      0.391227\n",
       "std        0.362698     0.369074      0.280289      0.351624\n",
       "min        0.000000     0.000000      0.000000      0.000000\n",
       "25%        0.062911     0.111642      0.085490      0.092142\n",
       "50%        0.348325     0.393829      0.220333      0.306221\n",
       "75%        0.798207     0.745034      0.446169      0.500000\n",
       "max        1.000000     1.000000      1.000000      1.000000"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results = evaluate_outputs(id2processed_text, gt_x)\n",
    "df_results.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0-shot for Bluesky, fewshot for X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "complexdata-kernel",
   "language": "python",
   "name": "complexdata-kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
